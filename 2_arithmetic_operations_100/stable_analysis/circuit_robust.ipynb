{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import partial\n",
    "from typing import Optional, List, Union, Literal, Tuple\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as utils\n",
    "from transformers import AutoTokenizer \n",
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline,get_circuit_logits\n",
    "from eap.attribute import attribute \n",
    "from eap.attribute import tokenize_plus\n",
    "from eap.metrics import logit_diff, direct_logit\n",
    "import re\n",
    "\n",
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['label']\n",
    "    \n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "    \n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "\n",
    "    logits = logits[idx, input_length - 1]\n",
    "    return logits\n",
    "\n",
    "\n",
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "model_name = 'pythia-1.4b-deduped'\n",
    "base_model_name = \"EleutherAI/pythia-1.4b-deduped\"\n",
    "config = AutoConfig.from_pretrained(base_model_name)\n",
    "hf_model = AutoModelForCausalLM.from_config(config)\n",
    "\n",
    "model = HookedTransformer.from_pretrained(model_name, device='cuda',hf_model=hf_model)\n",
    "\n",
    "model.cfg.use_split_qkv_input = True\n",
    "model.cfg.use_attn_result = True\n",
    "model.cfg.use_hook_mlp_in = True\n",
    "\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "ds = EAPDataset('/2_arithmetic_operations_100/stable_analysis/Split_data/Logical_Operations_Split_4.csv')\n",
    "dataloader = ds.to_dataloader(64)\n",
    "# Instantiate a graph with a model\n",
    "g = Graph.from_model(model)\n",
    "\n",
    "# Attribute using the model, graph, clean / corrupted data and labels, as well as a metric\n",
    "attribute(model, g, dataloader, partial(kl_divergence, loss=True, mean=True), method='EAP-IG', ig_steps=5)\n",
    "\n",
    "# Print total number of edges in the graph\n",
    "total_edges = len(g.edges)\n",
    "print(f\"Total number of edges: {total_edges}\")\n",
    "\n",
    "# Calculate 5% of the edges\n",
    "five_percent_edges = int(total_edges * 0.05)\n",
    "print(f\"5% of the edges: {five_percent_edges}\")\n",
    "g.apply_topn(five_percent_edges , absolute=True)\n",
    "g.prune_dead_nodes()\n",
    "g.to_json('/2_arithmetic_operations_100/stable_analysis/Split_circuits/random/graph_simplemath_1.4b_split4.json')\n",
    "\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "# Function to calculate faithfulness and percentage of model performance\n",
    "def calculate_faithfulness(model, g, dataloader, metric_fn):\n",
    "    # Evaluate baseline (full model performance)\n",
    "    baseline_performance = evaluate_baseline(model, dataloader, metric_fn).mean().item()\n",
    "\n",
    "    # Evaluate the discovered circuit's performance\n",
    "    circuit_performance = evaluate_graph(model, g, dataloader, metric_fn).mean().item()\n",
    "\n",
    "    # Calculate the absolute difference (faithfulness)\n",
    "    faithfulness = abs(baseline_performance - circuit_performance)\n",
    "\n",
    "    # Calculate the percentage of model performance achieved by the circuit\n",
    "    percentage_performance = (1 - faithfulness / baseline_performance) * 100\n",
    "\n",
    "    print(f\"Baseline performance: {baseline_performance}\")\n",
    "    print(f\"Circuit performance: {circuit_performance}\")\n",
    "    print(f\"Faithfulness: {faithfulness}\")\n",
    "    print(f\"Percentage of model performance achieved by the circuit: {percentage_performance:.2f}%\")\n",
    "\n",
    "    return faithfulness, percentage_performance\n",
    "\n",
    "# Define the KL divergence metric (from your code)\n",
    "metric_fn = partial(kl_divergence, loss=False, mean=False)\n",
    "\n",
    "# Calculate faithfulness and percentage performance\n",
    "faithfulness, percentage_performance = calculate_faithfulness(model, g, dataloader, metric_fn)\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def exact_match_accuracy(logits, corrupted_logits, input_lengths, labels):\n",
    "\n",
    "    batch_size = logits.size(0)\n",
    "    device = logits.device\n",
    "\n",
    "    # Get the positions of the last tokens in each sequence\n",
    "    positions = input_lengths - 1  # [batch_size]\n",
    "\n",
    "    # Gather the logits at these positions\n",
    "    last_logits = logits[torch.arange(batch_size), positions, :]  # [batch_size, vocab_size]\n",
    "\n",
    "    # Get the predicted tokens\n",
    "    predicted_tokens = last_logits.argmax(dim=-1)  # [batch_size]\n",
    "\n",
    "    # Convert predicted tokens to strings\n",
    "    predicted_strings = [model.to_string(token.item()).strip() for token in predicted_tokens]\n",
    "\n",
    "    # Convert labels to strings\n",
    "    labels_strings = []\n",
    "    for i in range(batch_size):\n",
    "        lab = labels[i]\n",
    "        if isinstance(lab, torch.Tensor):\n",
    "            lab = lab.item()\n",
    "        labels_strings.append(str(lab).strip())\n",
    "\n",
    "    # Compute correctness\n",
    "    correct = []\n",
    "    for pred_str, label_str in zip(predicted_strings, labels_strings):\n",
    "        if pred_str == label_str:\n",
    "            correct.append(1.0)\n",
    "        else:\n",
    "            correct.append(0.0)\n",
    "\n",
    "    return torch.tensor(correct, device=device)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "baseline_accuracy = evaluate_baseline(model, dataloader, exact_match_accuracy, quiet=True).mean().item()\n",
    "\n",
    "# Evaluate the graph model\n",
    "graph_accuracy = evaluate_graph(model, g, dataloader, exact_match_accuracy, quiet=True).mean().item()\n",
    "\n",
    "print(f\"Baseline model accuracy: {baseline_accuracy:.4f}; Graph model accuracy: {graph_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline\n",
    "from eap.attribute import attribute\n",
    "from eap.metrics import logit_diff\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "# Collate function for DataLoader\n",
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    return list(clean), list(corrupted), labels\n",
    "\n",
    "# Dataset class for loading data\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['label']\n",
    "\n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "\n",
    "# Helper function to extract logits at specific positions\n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "    return logits[idx, input_length - 1]\n",
    "\n",
    "# KL divergence loss function\n",
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results\n",
    "\n",
    "# Exact match accuracy metric\n",
    "def exact_match_accuracy(logits, corrupted_logits, input_lengths, labels):\n",
    "    batch_size = logits.size(0)\n",
    "    device = logits.device\n",
    "\n",
    "    # Get the positions of the last tokens in each sequence\n",
    "    positions = input_lengths - 1  # [batch_size]\n",
    "\n",
    "    # Gather the logits at these positions\n",
    "    last_logits = logits[torch.arange(batch_size), positions, :]  # [batch_size, vocab_size]\n",
    "\n",
    "    # Get the predicted tokens\n",
    "    predicted_tokens = last_logits.argmax(dim=-1)  # [batch_size]\n",
    "\n",
    "    # Convert predicted tokens to strings\n",
    "    predicted_strings = [model.to_string(token.item()).strip() for token in predicted_tokens]\n",
    "\n",
    "    # Convert labels to strings\n",
    "    labels_strings = []\n",
    "    for i in range(batch_size):\n",
    "        lab = labels[i]\n",
    "        if isinstance(lab, torch.Tensor):\n",
    "            lab = lab.item()\n",
    "        labels_strings.append(str(lab).strip())\n",
    "\n",
    "    # Compute correctness\n",
    "    correct = []\n",
    "    for pred_str, label_str in zip(predicted_strings, labels_strings):\n",
    "        if pred_str == label_str:\n",
    "            correct.append(1.0)\n",
    "        else:\n",
    "            correct.append(0.0)\n",
    "\n",
    "    return torch.tensor(correct, device=device)\n",
    "\n",
    "# Function to calculate faithfulness and percentage performance\n",
    "def calculate_faithfulness(model, g, dataloader, metric_fn):\n",
    "    baseline_performance = evaluate_baseline(model, dataloader, metric_fn).mean().item()\n",
    "    circuit_performance = evaluate_graph(model, g, dataloader, metric_fn).mean().item()\n",
    "    faithfulness = abs(baseline_performance - circuit_performance)\n",
    "    percentage_performance = (1 - faithfulness / baseline_performance) * 100\n",
    "    print(f\"Percentage of model performance achieved by the circuit: {percentage_performance:.2f}%\")\n",
    "    return faithfulness, percentage_performance\n",
    "\n",
    "split_data_path = '/2_arithmetic_operations_100/stable_analysis/Split_data'\n",
    "circuit_save_path = '/2_arithmetic_operations_100/stable_analysis/Split_circuits/pretrained'\n",
    "\n",
    "model_name = 'pythia-1.4b-deduped'\n",
    "model = HookedTransformer.from_pretrained(model_name, device='cuda')\n",
    "model.cfg.use_split_qkv_input = True\n",
    "model.cfg.use_attn_result = True\n",
    "model.cfg.use_hook_mlp_in = True\n",
    "\n",
    "tokenizer = model.tokenizer\n",
    "metric_fn = partial(kl_divergence, loss=False, mean=False)\n",
    "\n",
    "n_splits = 5\n",
    "batch_size = 64\n",
    "\n",
    "# Process each split\n",
    "for i in range(n_splits):\n",
    "    print(f\"Processing split {i} ...\")\n",
    "    dataset_path = os.path.join(split_data_path, f\"Logical_Operations_Split_{i}.csv\")\n",
    "    circuit_path = os.path.join(circuit_save_path, f\"graph_simplemath_1.4b_split{i}.json\")\n",
    "\n",
    "    ds = EAPDataset(dataset_path)\n",
    "    dataloader = ds.to_dataloader(batch_size=batch_size)\n",
    "    g = Graph.from_model(model)\n",
    "    attribute(model, g, dataloader, partial(kl_divergence, loss=True, mean=True), method='EAP-IG', ig_steps=5)\n",
    "\n",
    "    total_edges = len(g.edges)\n",
    "    print(f\"Total number of edges: {total_edges}\")\n",
    "\n",
    "    five_percent_edges = int(total_edges * 0.05)\n",
    "    print(f\"5% of the edges: {five_percent_edges}\")\n",
    "    g.apply_topn(five_percent_edges, absolute=True)\n",
    "    g.prune_dead_nodes()\n",
    "\n",
    "    g.to_json(circuit_path)\n",
    "    print(f\"Saved circuit to {circuit_path}\")\n",
    "\n",
    "    # Calculate faithfulness and percentage performance for the final graph\n",
    "    faithfulness, percentage_performance = calculate_faithfulness(model, g, dataloader, metric_fn)\n",
    "    baseline_accuracy = evaluate_baseline(model, dataloader, exact_match_accuracy, quiet=True).mean().item()\n",
    "    graph_accuracy = evaluate_graph(model, g, dataloader, exact_match_accuracy, quiet=True).mean().item()\n",
    "    print(f\"Baseline model accuracy: {baseline_accuracy:.4f}; Graph model accuracy: {graph_accuracy:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "from transformer_lens import HookedTransformer\n",
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline\n",
    "from eap.attribute import attribute\n",
    "from eap.metrics import logit_diff\n",
    "import re\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# Collate function for DataLoader\n",
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "# Dataset class for loading data\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['label']\n",
    "\n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "\n",
    "# Helper function to extract logits at specific positions\n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "    logits = logits[idx, input_length - 1]\n",
    "    return logits\n",
    "\n",
    "# KL divergence loss function\n",
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results\n",
    "\n",
    "# Exact match accuracy metric\n",
    "def exact_match_accuracy(logits, corrupted_logits, input_lengths, labels):\n",
    "    batch_size = logits.size(0)\n",
    "    device = logits.device\n",
    "    # Get the positions of the last tokens in each sequence\n",
    "    positions = input_lengths - 1\n",
    "    last_logits = logits[torch.arange(batch_size), positions, :]\n",
    "    predicted_tokens = last_logits.argmax(dim=-1)\n",
    "    predicted_strings = [model.to_string(token.item()).strip() for token in predicted_tokens]\n",
    "    labels_strings = []\n",
    "    for i in range(batch_size):\n",
    "        lab = labels[i]\n",
    "        if isinstance(lab, torch.Tensor):\n",
    "            lab = lab.item()\n",
    "        labels_strings.append(str(lab).strip())\n",
    "    correct = [1.0 if pred == lab else 0.0 for pred, lab in zip(predicted_strings, labels_strings)]\n",
    "    return torch.tensor(correct, device=device)\n",
    "\n",
    "# Function to calculate faithfulness and percentage performance\n",
    "def calculate_faithfulness(model, g, dataloader, metric_fn):\n",
    "    baseline_performance = evaluate_baseline(model, dataloader, metric_fn).mean().item()\n",
    "    circuit_performance = evaluate_graph(model, g, dataloader, metric_fn).mean().item()\n",
    "    faithfulness = abs(baseline_performance - circuit_performance)\n",
    "    percentage_performance = (1 - faithfulness / baseline_performance) * 100\n",
    "    print(f\"Percentage of model performance achieved by the circuit: {percentage_performance:.2f}%\")\n",
    "    return faithfulness, percentage_performance\n",
    "\n",
    "# ----------------------------\n",
    "# Finetuned 模型加载及 LoRA 权重合并\n",
    "# ----------------------------\n",
    "model_name = 'pythia-1.4b-deduped'\n",
    "base_model_path = \"EleutherAI/pythia-1.4b-deduped\"\n",
    "lora_weights_path = \"/2_arithmetic_operations_100/finetune_pythia_100/Peft/lora_results/r32a64/checkpoint-250/adapter_model.safetensors\"\n",
    "\n",
    "# 加载基础模型\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_path)\n",
    "# 加载 LoRA 权重\n",
    "lora_weights = load_file(lora_weights_path)\n",
    "\n",
    "scaling = 2  # 标准 LoRA 的缩放因子\n",
    "scaling_extra = 2   # 增强 LoRA 的缩放因子\n",
    "\n",
    "def merge_lora_weights(model, lora_weights, scaling=2.0, scaling_extra=2.0):\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name.rsplit(\".\", 1)[0] \n",
    "        if \"bias\" in name:\n",
    "            if name in lora_weights and lora_weights[name].shape == param.data.shape:\n",
    "                param.data += lora_weights[name].to(param.device)\n",
    "                print(f\"Applied LoRA bias to: {name}\")\n",
    "            else:\n",
    "                print(f\"Skipped LoRA bias update: {name}\")\n",
    "            continue\n",
    "\n",
    "        lora_A_key = f\"{layer_name}.lora_A\"\n",
    "        lora_B_key = f\"{layer_name}.lora_B\"\n",
    "        lora_A_extra_key = f\"{layer_name}.lora_A_extra\"\n",
    "        lora_B_extra_key = f\"{layer_name}.lora_B_extra\"\n",
    "\n",
    "        delta_weight = None\n",
    "\n",
    "        if lora_A_key in lora_weights and lora_B_key in lora_weights:\n",
    "            lora_A = lora_weights[lora_A_key].to(param.device)\n",
    "            lora_B = lora_weights[lora_B_key].to(param.device)\n",
    "            delta_weight = torch.matmul(lora_B, lora_A) * scaling\n",
    "            print(f\"Applied standard LoRA to: {layer_name}\")\n",
    "\n",
    "        if lora_A_extra_key in lora_weights and lora_B_extra_key in lora_weights:\n",
    "            lora_A_extra = lora_weights[lora_A_extra_key].to(param.device)\n",
    "            lora_B_extra = lora_weights[lora_B_extra_key].to(param.device)\n",
    "            extra_delta = torch.matmul(lora_B_extra, lora_A_extra) * scaling_extra\n",
    "            delta_weight = delta_weight + extra_delta if delta_weight is not None else extra_delta\n",
    "            print(f\"Applied extra LoRA to: {layer_name}\")\n",
    "\n",
    "        if delta_weight is not None and delta_weight.shape == param.data.shape:\n",
    "            param.data += delta_weight\n",
    "            print(f\"Updated weight: {name}\")\n",
    "        elif delta_weight is not None:\n",
    "            print(f\"Shape mismatch: {layer_name} - ΔW {delta_weight.shape}, param {param.shape}\")\n",
    "        else:\n",
    "            print(f\"No LoRA update for: {name}\")\n",
    "    return model\n",
    "\n",
    "hf_model = merge_lora_weights(base_model, lora_weights)\n",
    "\n",
    "model = HookedTransformer.from_pretrained(model_name, device='cuda', hf_model=hf_model)\n",
    "model.cfg.use_split_qkv_input = True\n",
    "model.cfg.use_attn_result = True\n",
    "model.cfg.use_hook_mlp_in = True\n",
    "# Prepare tokenizer and metric\n",
    "tokenizer = model.tokenizer\n",
    "metric_fn = partial(kl_divergence, loss=False, mean=False)\n",
    "\n",
    "split_data_path = '/2_arithmetic_operations_100/stable_analysis/Split_data'\n",
    "circuit_save_path = '/2_arithmetic_operations_100/stable_analysis/Split_circuits/finetuned'\n",
    "os.makedirs(circuit_save_path, exist_ok=True)\n",
    "\n",
    "n_splits = 5\n",
    "batch_size = 64\n",
    "\n",
    "for i in range(n_splits):\n",
    "    print(f\"\\nProcessing split {i} ...\")\n",
    "    dataset_path = os.path.join(split_data_path, f\"Logical_Operations_Split_{i}.csv\")\n",
    "    circuit_path = os.path.join(circuit_save_path, f\"graph_simplemath_1.4b_split{i}.json\")\n",
    "\n",
    "    # Load dataset\n",
    "    ds = EAPDataset(dataset_path)\n",
    "    dataloader = ds.to_dataloader(batch_size=batch_size)\n",
    "\n",
    "    # Instantiate a graph with the model\n",
    "    g = Graph.from_model(model)\n",
    "\n",
    "    # Attribute using the model, graph, and data\n",
    "    attribute(model, g, dataloader, partial(kl_divergence, loss=True, mean=True), method='EAP-IG', ig_steps=5)\n",
    "\n",
    "    # Print total number of edges in the graph\n",
    "    total_edges = len(g.edges)\n",
    "    print(f\"Total number of edges: {total_edges}\")\n",
    "\n",
    "    # Calculate 5% of the edges and apply pruning\n",
    "    five_percent_edges = int(total_edges * 0.05)\n",
    "    print(f\"5% of the edges: {five_percent_edges}\")\n",
    "    g.apply_topn(five_percent_edges, absolute=True)\n",
    "    g.prune_dead_nodes()\n",
    "\n",
    "    # Save the graph (circuit)\n",
    "    g.to_json(circuit_path)\n",
    "    print(f\"Saved circuit to {circuit_path}\")\n",
    "\n",
    "    # Evaluate faithfulness and accuracy\n",
    "    faithfulness, percentage_performance = calculate_faithfulness(model, g, dataloader, metric_fn)\n",
    "    baseline_accuracy = evaluate_baseline(model, dataloader, exact_match_accuracy, quiet=True).mean().item()\n",
    "    graph_accuracy = evaluate_graph(model, g, dataloader, exact_match_accuracy, quiet=True).mean().item()\n",
    "    print(f\"Baseline model accuracy: {baseline_accuracy:.4f}; Graph model accuracy: {graph_accuracy:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_circuits(circuit_dir, n_splits):\n",
    "    circuits = []\n",
    "    for i in range(n_splits):\n",
    "        file_path = os.path.join(circuit_dir, f\"graph_simplemath_1.4b_split{i}.json\")\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            edges = data.get(\"edges\", [])\n",
    "            edge_set = set(tuple(edge) for edge in edges)\n",
    "            circuits.append(edge_set)\n",
    "    return circuits\n",
    "\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    union = set1.union(set2)\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    intersection = set1.intersection(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def compute_pairwise_jaccard(circuits):\n",
    "    similarities = []\n",
    "    n = len(circuits)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            sim = jaccard_similarity(circuits[i], circuits[j])\n",
    "            similarities.append(sim)\n",
    "    return similarities\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "fine_tuned_dir = \"/2_arithmetic_operations_100/stable_analysis/Split_circuits/f1\"\n",
    "pre_trained_dir = \"/2_arithmetic_operations_100/stable_analysis/Split_circuits/p1\"\n",
    "random_dir = \"/2_arithmetic_operations_100/stable_analysis/Split_circuits/r1\"\n",
    "\n",
    "\n",
    "circuits_finetuned = load_circuits(fine_tuned_dir, n_splits)\n",
    "circuits_pretrained = load_circuits(pre_trained_dir, n_splits)\n",
    "circuits_random = load_circuits(random_dir, n_splits)\n",
    "\n",
    "\n",
    "jacc_finetuned = compute_pairwise_jaccard(circuits_finetuned)\n",
    "jacc_pretrained = compute_pairwise_jaccard(circuits_pretrained)\n",
    "jacc_random = compute_pairwise_jaccard(circuits_random)\n",
    "\n",
    "\n",
    "colors = [\"#104670\", \"#E47159\", \"#DFA085\"]\n",
    "markers = [\"o\", \"s\", \"D\"]\n",
    "labels_list = [\"Fine-tuned\", \"Pre-trained\", \"Random\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "model_indices = [0, 1, 2]\n",
    "all_jacc = [jacc_finetuned, jacc_pretrained, jacc_random]\n",
    "\n",
    "for idx, similarities in zip(model_indices, all_jacc):\n",
    "\n",
    "    x_vals = np.random.normal(loc=idx, scale=0.04, size=len(similarities))\n",
    "    plt.scatter(x_vals, similarities, color=colors[idx], marker=markers[idx],\n",
    "                label=labels_list[idx], alpha=0.7)\n",
    "    mean_sim = np.mean(similarities)\n",
    "    plt.hlines(mean_sim, idx - 0.2, idx + 0.2, colors=colors[idx], linestyles='dashed', linewidth=2)\n",
    "    print(f\"{labels_list[idx]}: mean Jaccard similarity = {mean_sim:.4f}\")\n",
    "\n",
    "plt.xticks(model_indices, labels_list, fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Model\", fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Robustness Score\", fontsize=16, fontweight='bold')\n",
    "plt.title(\"Robustness Analysis (Add/Sub)\", fontsize=18, fontweight='bold')\n",
    "\n",
    "\n",
    "plt.ylim(0.5, 1)\n",
    "plt.yticks(fontsize=14, fontweight='bold')\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.legend(fontsize=12, frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"robust_rebuttal.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
